{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC OpenStreetMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project:** Wrangle OpenStreetMap Data\n",
    "\n",
    "**Submitted by:** Bharath Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the report, I will wrangle the OpenStreetMap data of Manhattan, New York, United States.\n",
    "\n",
    "First, I will audit the dataset to find out if there is any problem within the dataset that needs to be fixed. Next, I will use SQL queries to obtain an overview of the dataset. Last, I will provide some ideas to further improve and analyze the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Area\n",
    "\n",
    "New York (Manhattan), New York, United States I've obtained [a custom map](NYC.osm) that includes the Manhattan borough of New York City through Mapzen. I have chosen this area because I am living in Jersey City and I use to visit NYC during my weekends. I would like to find out if I will be able to find some interesting facts about the city I love by investigating the OpenStreetMap data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSM_FILE = 'NYC.osm'\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import datetime as dt\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import schema\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, Float, String, MetaData, ForeignKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Auditing and Problems Encountered in the Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Map Extracts Included Surrounding Areas and Inconsistent Zip Codes\n",
    "\n",
    "**Examples: \"10001\", \"10001-2062\", \"NY 11106\", \"New York, NY 10065\"**\n",
    "\n",
    "Because of the way in which the data extract is generated, areas that surrounding Manhattan are also included in this dataset. I suspect that the dataset includes parts of other New York City boroughs and some parts of New Jersey. To confirm this, I will look at the zip codes distribution of our dataset. \n",
    "\n",
    "Because there is inconsistency in the zip code formats, I will fix that before aggregate the zip codes. I will use a update_zip_code function to update the zip code formats to a 5-digit zip code format (e.g. \"10001\") for more consistent queries. If more than one zip code is listed for any given address,I will keep only the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#      Helper Functions for Auditing Zip Codes       #\n",
    "# ================================================== #\n",
    "def is_zip_code(elem):\n",
    "    return (elem.attrib['k'] == 'addr:postcode')\n",
    "\n",
    "def audit_zip_codes(zip_code_formats, zip_codes_distribution, zip_code):\n",
    "    '''Audit zip codes\n",
    "    \n",
    "    This function updates two dictionaries showing the distribution of zip code formats\n",
    "    and the distribution of zip code areas.\n",
    "    \n",
    "    Arg:\n",
    "    zip_code_formats: A dictionary of zip code format: counts of zip code in that format\n",
    "    zip_codes_distribution: A dictionary of zip code area name: counts of zip codes in that area\n",
    "    zip_code: A zip code\n",
    "    '''\n",
    "    \n",
    "    # Audit zip code formats\n",
    "    # Convert any digit to an 'X' sign (e.g. 'NY 10001' becomes 'NY XXXXX')\n",
    "    zip_code_format = re.sub('\\d', 'X', zip_code)\n",
    "    zip_code_formats[zip_code_format] += 1\n",
    "    \n",
    "    # Audit zip code areas\n",
    "    # Convert zip code to its corresponding area name\n",
    "    zip_code = re.sub('\\D', '', zip_code) # Only look at zip code digits\n",
    "    if re.match(r'^10[0-2]', zip_code): # Manhattan: 100XX, 101XX, 102XX\n",
    "        zip_codes_distribution['Manhattan'] += 1\n",
    "    elif re.match(r'^104', zip_code): # Bronx: 104XX\n",
    "        zip_codes_distribution['Bronx'] += 1\n",
    "    elif re.match(r'^112', zip_code): # Brooklyn: 112XX\n",
    "        zip_codes_distribution['Brooklyn'] += 1\n",
    "    elif re.match(r'^103', zip_code): # Staten Island: 103XX\n",
    "        zip_codes_distribution['Staten Island'] += 1\n",
    "    elif re.match(r'^11', zip_code): # Queens: 11XXX\n",
    "        zip_codes_distribution['Queens'] += 1\n",
    "    elif re.match(r'^07', zip_code): # New Jersey: 07XXX\n",
    "        zip_codes_distribution['New Jersey'] += 1\n",
    "    else:\n",
    "        zip_codes_distribution['Other'] += 1\n",
    "        \n",
    "# ================================================== #\n",
    "#         Functions for Updating Zip Codes           #\n",
    "# ================================================== #\n",
    "def update_zip_code(zip_code):\n",
    "    '''Update zip code format to five digits only\n",
    "    \n",
    "    This funtion is used to correct inconsistent zip code formats during XML to csv conversion\n",
    "    \n",
    "    Arg:\n",
    "    zip_code: a raw zip code from the dataset\n",
    "    \n",
    "    Return:\n",
    "    zip_code: an updated zip code consists with 5 digits \n",
    "    '''\n",
    "    # Update zip code format to five digits 'XXXXX'\n",
    "    if re.search(r';', zip_code):\n",
    "        zip_code = zip_code.split(';')[0] # Keep the first zip code for 'XXXXX;XXXXX' format\n",
    "    digits = re.sub('\\D', '', zip_code)\n",
    "    if len(digits) ==  5: \n",
    "        zip_code = digits # 'XXXXX' stays the same\n",
    "    elif len(digits) == 9: \n",
    "        zip_code = digits[:5] # 'XXXXX-XXXX' only keeps the first 5 digits\n",
    "    return zip_code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Inconsistent Street Types\n",
    "\n",
    "**Examples: \"Street\", \"street\", \"St\", \"St.\"**\n",
    "\n",
    "The street types of addresses in the dataset are inconstistent in terms of abbreviations and lower/upper cases. First by auditing the street types I will build a mapping to map different types of street type abbreviations and lower/upper cases to non-abbreviated street types with first letter capitalized (e.g. \"Street\", \"Avenue\"). Then I will use a update_name function to update the better updated addresses during XML to csv conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#     Helper Functions for Auditing Street Types     #\n",
    "# ================================================== #\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# Expected good street types\n",
    "expected = ['Street', 'Avenue', 'Boulevard', 'Drive', 'Court', \n",
    "            'Place', 'Square', 'Lane', 'Road', 'Trail', \n",
    "            'Parkway', 'Commons', 'Broadway', 'Highway', 'Crescent', \n",
    "            'Park', 'Plaza', 'Terrace', 'Way', 'Walk', \n",
    "            'East', 'South', 'West', 'North', 'Alley', \n",
    "            'Circle', 'Center']\n",
    "\n",
    "# Mapping from bad street types to good street types\n",
    "mapping = { 'Americas\\n': 'Americas',\n",
    "            'ave': 'Avenue',\n",
    "            'avenue': 'Avenue',\n",
    "            'Ave': 'Avenue',\n",
    "            'Ave.': 'Avenue',\n",
    "            'Avene': 'Avenue',\n",
    "            'Aveneu': 'Avenue',\n",
    "            'Blv': 'Boulevard',\n",
    "            'Blvd': 'Boulevard',\n",
    "            'Broadway.': 'Broadway',\n",
    "            'Ctr': 'Center',\n",
    "            'Plz': 'Plaza',\n",
    "            'Rd.': 'Road',\n",
    "            'S': 'South',\n",
    "            'st': 'Street',\n",
    "            'St': 'Street',\n",
    "            'St.': 'Street',\n",
    "            'Steet': 'Street',\n",
    "            'street': 'Street',\n",
    "            'Streeet': 'Street',\n",
    "            'ST': 'Street'\n",
    "            }\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == 'addr:street')\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    '''Audit street type\n",
    "    \n",
    "    This function updates the dictionary showing the street type and its corresponding\n",
    "    set of street names with that street type.\n",
    "    \n",
    "    Arg:\n",
    "    street_types: A dictionary of street type: a set of street names wtih that street type\n",
    "    street_name: A street name\n",
    "    '''\n",
    "    \n",
    "    matched = street_type_re.search(street_name)\n",
    "    if matched:\n",
    "        street_type = matched.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "            \n",
    "# ================================================== #\n",
    "#        Functions for Updating Street Types         #\n",
    "# ================================================== # \n",
    "# Funtion to be used to correct inconsistent street types during XML to csv conversion\n",
    "def update_name(name, mapping):\n",
    "    '''Update street name to good format\n",
    "    \n",
    "    This funtion is used to correct inconsistent street name formats during XML to csv conversion\n",
    "    \n",
    "    Arg:\n",
    "    name: a raw street name from the dataset\n",
    "    mapping: a dictionary of bad street type: good street type\n",
    "    \n",
    "    Return:\n",
    "    name: an updated street name of full street type name with the first letter capitalized\n",
    "    '''\n",
    "    street_kind = name.split(' ')[-1] # Last word of address is the street type\n",
    "    if street_kind in mapping:\n",
    "        street_kind_better = mapping[street_kind]\n",
    "        name = name.replace(street_kind, street_kind_better)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Inconsistent Phone Number Formats\n",
    "\n",
    "**Examples: \"(212) 333-3100\", \"+1 212 228-7732\", \"2122391222\", \"718-731-3100\"**\n",
    "\n",
    "The phone number formats in the dataset are also inconsistent. I will update the phone number format to +1-XXX-XXX-XXXX by using a update_phone_number function, and later I will use this during XML to csv conversion. If more than one phone number is listed for any given address, I will only keep the first one for more consistent queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#    Helper Functions for Auditing Phone Numbers     #\n",
    "# ================================================== #            \n",
    "def is_phone(elem):\n",
    "    return (elem.attrib['k'] == \"phone\" or elem.attrib['k'] == \"contact:phone\")\n",
    "\n",
    "def audit_phone_number_formats(phone_number_formats, phone_number):\n",
    "    '''Audit phone numbers\n",
    "    \n",
    "    This function updates a dictionary showing the distribution of phone number formats.\n",
    "    \n",
    "    Arg:\n",
    "    phone_number_formats: A dictionary of phone number format: counts of phone numbers of that format\n",
    "    phone_number: A phone number\n",
    "    '''\n",
    "    \n",
    "    # Convert any digit to an 'X' sign (e.g. '(212) 333-3100' becomes '(XXX) XXX-XXXX')\n",
    "    phone_number_format = re.sub('\\d', 'X', phone_number)\n",
    "    phone_number_formats[phone_number_format] += 1\n",
    "\n",
    "# ================================================== #\n",
    "#       Functions for Updating Phone Numbers         #\n",
    "# ================================================== # \n",
    "# Funtion to be used to correct inconsistent phone number formats during XML to csv conversion\n",
    "def update_phone_number(phone_number):\n",
    "    '''Update phone number format to '+1-XXX-XXX-XXXX'\n",
    "    \n",
    "    This funtion is used to correct inconsistent phone number formats during XML to csv conversion\n",
    "    \n",
    "    Arg:\n",
    "    phone_number: a raw phone number from the dataset\n",
    "    \n",
    "    Return:\n",
    "    phone_number: an updated phone number with the format '+1-XXX-XXX-XXXX'\n",
    "    \n",
    "    '''\n",
    "    # Keep the first phone number if more than one is present\n",
    "    if re.search(r';', phone_number):\n",
    "        phone_number = phone_number.split(';')[0] # Phone numbers are separated by ';'\n",
    "    elif re.search(r'/', phone_number):\n",
    "        phone_number = phone_number.split('/')[0] # Phone numbers are separated by '/'\n",
    "    \n",
    "    digits = re.sub('\\D', '', phone_number)\n",
    "    if len(digits) == 11: # 1XXXXXXXXXX\n",
    "        return '+' + digits[0] + '-' + digits[1:4] + '-' + digits[4:7] + '-' + digits[7:]\n",
    "    elif len(digits) == 10: # XXXXXXXXXX\n",
    "        return '+1' + '-' + digits[:3] + '-' + digits[3:6] + '-' + digits[6:]\n",
    "    elif len(digits) == 12: # 01XXXXXXXXXX\n",
    "        return '+' + digits[1] + '-' + digits[2:5] + '-' + digits[5:8] + '-' + digits[8:]\n",
    "    elif len(digits) == 13: # 001XXXXXXXXXX\n",
    "        return '+' + digits[2] + '-' + digits[3:6] + '-' + digits[6:9] + '-' + digits[9:]\n",
    "    else:\n",
    "        return phone_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Auditing zip codes:\n",
      "==================================================\n",
      "Zip code formats:\n",
      "{'(XXX) XXX-XXXX': 1,\n",
      " 'NY XXXXX': 12,\n",
      " 'New York, NY XXXXX': 1,\n",
      " 'XX': 2,\n",
      " 'XXX': 1,\n",
      " 'XXXXX': 235544,\n",
      " 'XXXXX-XXXX': 13,\n",
      " 'XXXXX;XXXXX': 2,\n",
      " 'XXXXXX': 1}\n",
      "\n",
      "--------------------------------------------------\n",
      "Zip code distribution:\n",
      "{'Bronx': 28614,\n",
      " 'Brooklyn': 90712,\n",
      " 'Manhattan': 58284,\n",
      " 'New Jersey': 209,\n",
      " 'Other': 5,\n",
      " 'Queens': 57753}\n",
      "\n",
      "==================================================\n",
      "Auditing street types:\n",
      "==================================================\n",
      "{'1': {'Grand Concourse #1', 'Graham Avenue #1'},\n",
      " '10024': {'West 80th Street NYC 10024'},\n",
      " '11217': {'305 Schermerhorn St., Brooklyn, NY 11217'},\n",
      " '1204': {'Journal Square #1204'},\n",
      " '1801': {'505th 8th Avenue Suite 1801'},\n",
      " '1807': {'5th AVE 1807'},\n",
      " '1st': {'1st'},\n",
      " '2': {'55 Riverwalk Pl #2'},\n",
      " '200': {'200'},\n",
      " '205': {'Broadway #205'},\n",
      " '21G': {'East 80th Street, 21G'},\n",
      " '27th': {'W 27th'},\n",
      " '29th': {'29th'},\n",
      " '2N': {'400th West 20th St., Suite 2N'},\n",
      " '2R': {'408 West 22nd Street #2R'},\n",
      " '3': {'Hanover Square #3', 'Old Route 3'},\n",
      " '306': {'West 30th Street Suite 306'},\n",
      " '402': {'Maiden Ln #402'},\n",
      " '41st': {'41st'},\n",
      " '42nd': {'West 42nd'},\n",
      " '4B': {'Union Avenue 4B'},\n",
      " '500': {'Main St., Suite 500'},\n",
      " '506': {'Broadway #506'},\n",
      " '50th': {'50th'},\n",
      " '633': {'633'},\n",
      " '7th': {'32nd street with 7th'},\n",
      " '800a': {'W 36th St #800a'},\n",
      " '861': {'861'},\n",
      " 'A': {'Cypress Avenue #A', 'Avenue A'},\n",
      " 'Americas': {'Avenue Of The Americas',\n",
      "              'Avenue of Americas',\n",
      "              'Avenue of the Americas',\n",
      "              'Avenue of the Americas\\n'},\n",
      " 'Atrium': {'Broadway Atrium'},\n",
      " 'Ave': {'10th Ave',\n",
      "         '3rd Ave',\n",
      "         '4th Ave',\n",
      "         '5th Ave',\n",
      "         '6th Ave',\n",
      "         'Anderson Ave',\n",
      "         'Bergenline Ave',\n",
      "         'Columbus Ave',\n",
      "         'Hudson Ave',\n",
      "         'Morgan Ave',\n",
      "         'Norman Ave',\n",
      "         'Park Ave',\n",
      "         'Third Ave',\n",
      "         'Willow Ave'},\n",
      " 'Ave.': {'Washington Ave.'},\n",
      " 'Avene': {'Nostrand Avene', '8th Avene', 'Madison Avene'},\n",
      " 'Aveneu': {'St. Nicholas Aveneu'},\n",
      " 'Avenue,#392': {'Columbus Avenue,#392'},\n",
      " 'B': {'Avenue B', 'W 47th St #B'},\n",
      " 'Blv.': {'John F. Kennedy Blv.'},\n",
      " 'Blvd': {'Marin Blvd', 'Queens Blvd'},\n",
      " 'Bowery': {'The Bowery', 'Bowery'},\n",
      " 'Bridge': {'Harlem River Park Bridge'},\n",
      " 'Broadway.': {'Broadway.'},\n",
      " 'Bush': {'Ploughmans Bush'},\n",
      " 'Bushwick': {'Bushwick'},\n",
      " 'C': {'Avenue C', '2nd Street #C'},\n",
      " 'Clinton': {'Clinton'},\n",
      " 'Concourse': {'Grand Concourse'},\n",
      " 'Ctr': {'Harborside Fin Ctr'},\n",
      " 'D': {'Avenue D'},\n",
      " 'Expressway': {'Cross Bronx Expressway'},\n",
      " 'Extension': {'Eastern Parkway Extension', 'Flatbush Avenue Extension'},\n",
      " 'Finest': {'Avenue Of The Finest'},\n",
      " 'Floor': {'Wall Street 12th Floor'},\n",
      " 'Floor)': {'Manhattan Avenue (2nd Floor)'},\n",
      " 'Fulton': {'Old Fulton'},\n",
      " 'Gratta': {'Gratta'},\n",
      " 'Heights': {'Columbia Heights'},\n",
      " 'Highline': {'Highline'},\n",
      " 'Hill': {'Fort George Hill'},\n",
      " 'Hudson': {'Castle Point on Hudson'},\n",
      " 'Island': {'Randalls Island', 'Wards Island', 'Governors Island'},\n",
      " 'John': {'Avenue Saint John'},\n",
      " 'Lafayette': {'Lafayette'},\n",
      " 'Level': {'Madison Ave Arcage Level'},\n",
      " 'Loop': {'14th Street Loop',\n",
      "          'Charles Gay Loop',\n",
      "          'Sunken Garden Loop',\n",
      "          'Wards Meadow Loop'},\n",
      " 'Macdougal': {'Macdougal'},\n",
      " 'Mall': {'Centre Mall'},\n",
      " 'MetroTech': {'MetroTech'},\n",
      " 'Mews': {'Washington Mews', 'Greenwich Mews'},\n",
      " 'NY': {'405 West 23rd Street, New York, NY',\n",
      "        '54th W 39th St New York, NY',\n",
      "        'West 49th Street New York NY'},\n",
      " 'Oval': {'Grand Army Plaza Oval', 'Stuyvesant Oval', 'Fordham Hill Oval'},\n",
      " 'PH': {'Harrison Street Suite PH'},\n",
      " 'Piers': {'Northside Piers'},\n",
      " 'Plz': {'University Plz'},\n",
      " 'Rd': {'43rd Rd'},\n",
      " 'Rico': {'Avenue Of Puerto Rico'},\n",
      " 'Roadbed': {'Delancey Street Eb Roadbed',\n",
      "             'Gd Concourse Northbound Roadbed',\n",
      "             'Park Avenue Northbound Roadbed'},\n",
      " 'Row': {'Park Row'},\n",
      " 'S': {'Central Park S', 'Van Cortlandt Park S', 'Park Avenue S'},\n",
      " 'ST': {'N 9th ST'},\n",
      " 'Slip': {'Catherine Slip',\n",
      "          'Coenties Slip',\n",
      "          'Old Slip',\n",
      "          'Peck Slip',\n",
      "          'Pike Slip',\n",
      "          'Rutgers Slip'},\n",
      " 'St': {'1st St',\n",
      "        '205 W 58th St',\n",
      "        '2nd St',\n",
      "        '362nd Grand St',\n",
      "        '3rd St',\n",
      "        '40 W 94th St',\n",
      "        '4th St',\n",
      "        '56th St',\n",
      "        '6th St',\n",
      "        '7th St',\n",
      "        '8th St',\n",
      "        '9th St',\n",
      "        'Adams St',\n",
      "        'Bloomfield St',\n",
      "        'Clinton St',\n",
      "        'Court St',\n",
      "        'E 43rd St',\n",
      "        'East Houston St',\n",
      "        'Garden St',\n",
      "        'Grand St',\n",
      "        'Hudson St',\n",
      "        'Jackson St',\n",
      "        'Jefferson St',\n",
      "        'Madison St',\n",
      "        'Monroe St',\n",
      "        'N 7th St',\n",
      "        'Newark St',\n",
      "        'River St',\n",
      "        'Schermerhorn St',\n",
      "        'Smith St & Bergen St',\n",
      "        'State St & Water St',\n",
      "        'Union St',\n",
      "        'W 57th St',\n",
      "        'Washington St',\n",
      "        'West 32nd St',\n",
      "        'Wooster St'},\n",
      " 'St.': {'11th St.',\n",
      "         '13th St.',\n",
      "         '9th St.',\n",
      "         'Devoe St.',\n",
      "         'E. 54th St.',\n",
      "         'East 73rd St.',\n",
      "         'East 86th St.',\n",
      "         'Harrison St.',\n",
      "         'Henry St.',\n",
      "         'Schermerhorn St.',\n",
      "         'South 4th St.',\n",
      "         'Warren St.',\n",
      "         'Washington St.',\n",
      "         'West 44th St.'},\n",
      " 'Steet': {'West 8th Steet', 'West 25th Steet'},\n",
      " 'Streeet': {'Johnson Streeet'},\n",
      " 'Terminal': {'East 42nd Street at Grand Central Terminal',\n",
      "              'Grand Central Terminal'},\n",
      " 'Track': {'Track'},\n",
      " 'USA': {'424 5th Avenue, 10018 NY, USA'},\n",
      " 'Unidos': {'519 9th Ave, New York, NY 10018, Estados Unidos'},\n",
      " 'Uniti': {'3rd Ave, New York, NY 10028, Stati Uniti'},\n",
      " 'Vanderbilt': {'Vanderbilt'},\n",
      " 'Village': {'Washington Square Village'},\n",
      " 'Walkway': {'Hoboken Newport Walkway- Hudson River Waterfront Walkway'},\n",
      " 'Warren': {'Warren'},\n",
      " 'Willoughby': {'Willoughby'},\n",
      " 'Woodside': {'Woodside'},\n",
      " 'ave': {'10th ave',\n",
      "         '110 West 51st at 6 ave',\n",
      "         '11th ave',\n",
      "         '5th ave',\n",
      "         '6th ave'},\n",
      " 'avenue': {'Utica avenue', '5th avenue', '2nd avenue', 'Bedford avenue'},\n",
      " 'bus_stop': {'bus_stop'},\n",
      " 'st': {'Union st', 'W 35th st', 'South 4th st'},\n",
      " 'street': {'5th street',\n",
      "            'Columbia street',\n",
      "            'E 45th street',\n",
      "            'East 5th street',\n",
      "            'East 65th street',\n",
      "            'Hudson street',\n",
      "            'Lafayette street',\n",
      "            'Mott street',\n",
      "            'Mulberry street',\n",
      "            'Pearl street',\n",
      "            'Rivington street',\n",
      "            'Steinway street',\n",
      "            'Union street',\n",
      "            'W. 44th street',\n",
      "            'West 51st street',\n",
      "            'West 57th street'}}\n",
      "\n",
      "==================================================\n",
      "Auditing phone number formats:\n",
      "==================================================\n",
      "{'(XXX) XXX - XXXX': 3,\n",
      " '(XXX) XXX XXXX': 8,\n",
      " '(XXX) XXX-XXX': 1,\n",
      " '(XXX) XXX-XXXX': 372,\n",
      " '(XXX) XXX-XXXX ': 1,\n",
      " '(XXX)-XXX-XXXX': 4,\n",
      " '(XXX)XXX-XXXX': 10,\n",
      " '+(XXX) XXX-XXXX': 1,\n",
      " '+X  (XXX) XXX-XXXX': 1,\n",
      " '+X  XXX  XXX XXXX': 1,\n",
      " '+X  XXX XXX XXXX': 1,\n",
      " '+X (XXX) XXX-XXXX': 53,\n",
      " '+X (XXX)XXX-XXXX': 1,\n",
      " '+X XXX XXX XX XX': 2,\n",
      " '+X XXX XXX XXXX': 259,\n",
      " '+X XXX XXX-XXXX': 165,\n",
      " '+X XXX XXXX XXX': 1,\n",
      " '+X XXX XXXXXX': 1,\n",
      " '+X XXX XXXXXXX': 52,\n",
      " '+X XXX-XXX-XXXX': 106,\n",
      " '+X XXX. XXX. XXXX': 1,\n",
      " '+X XXX.XXX.XXXX': 12,\n",
      " '+X XXX.XXX.XXXX;+X XXX.XXX.XXXX': 1,\n",
      " '+X XXX/XXX/XXXX': 1,\n",
      " '+X XXXX XX XXXX': 1,\n",
      " '+X XXXXXXXXXX': 2,\n",
      " '+X-(XXX)XXX-XXXX': 2,\n",
      " '+X-XXX-XXX-XXXX': 84,\n",
      " '+X-XXX-XXX-XXXX;+X-XXX-XXX-XXXX': 1,\n",
      " '+X-XXX-XXX-XXXX;+X-XXX-XXX-XXXX;+X-XXX-XXX-XXXX': 1,\n",
      " '+X-XXX.XXX.XXXX': 1,\n",
      " '+X.XXXXXXXXXX': 1,\n",
      " '+XX': 3,\n",
      " '+XX XXX XXX XXXX': 1,\n",
      " '+XXXX-XXX-XXXX': 2,\n",
      " '+XXXXXXXXXXX': 34,\n",
      " 'X (XXX) XXX-XXXX': 12,\n",
      " 'X XXX XXX XXXX': 3,\n",
      " 'X XXX-XXX-XXXX': 1,\n",
      " 'X-XXX-XXX-XXXX': 13,\n",
      " 'X-XXX-XXX-XXXX / XXX-XXX-XXXX': 1,\n",
      " 'X-XXX.XXX-XXXX': 1,\n",
      " 'X.XXX.XXX.XXXX': 3,\n",
      " 'XXX  XXX XXXX': 1,\n",
      " 'XXX XXX XXXX': 91,\n",
      " 'XXX XXX-XXXX': 6,\n",
      " 'XXX XXX-XXXX; XXX XXX-XXXX;XXX XXX-XXXX': 1,\n",
      " 'XXX XXX-XXXXXXX': 1,\n",
      " 'XXX XXXXXXX': 1,\n",
      " 'XXX(XXX)XXX-XXXX': 1,\n",
      " 'XXX(XXX)XXXXXXX': 1,\n",
      " 'XXX) XXX-XXXX': 6,\n",
      " 'XXX-XXX-XXX': 1,\n",
      " 'XXX-XXX-XXX-XXXX': 3,\n",
      " 'XXX-XXX-XXXX': 164,\n",
      " 'XXX-XXX-XXXX \\u200e': 1,\n",
      " 'XXX-XXX-XXXX/XXXX': 1,\n",
      " 'XXX-XXX-XXXX;XXX-XXX-XXXX': 1,\n",
      " 'XXX.XXX.XXXX': 15,\n",
      " 'XXX.XXX.XXXXXX': 1,\n",
      " 'XXX.XXX.hXXXX': 1,\n",
      " 'XXXXXXXXXX': 92,\n",
      " 'XXXXXXXXXXX': 6,\n",
      " 'XXXXXXXXXXXXX': 1}\n"
     ]
    }
   ],
   "source": [
    "# ================================================== #\n",
    "#                      Auditing                      #\n",
    "# ================================================== # \n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, 'r', encoding=\"utf8\")\n",
    "    \n",
    "    street_types = defaultdict(set)\n",
    "    phone_number_formats = defaultdict(int)\n",
    "    zip_codes_distribution = defaultdict(int)\n",
    "    zip_code_formats = defaultdict(int)\n",
    "    \n",
    "    for event, elem in ET.iterparse(osm_file, events=('start',)):\n",
    "\n",
    "        if elem.tag == 'node' or elem.tag == 'way':\n",
    "            for tag in elem.iter('tag'):\n",
    "                \n",
    "                # Audit zip codes\n",
    "                if is_zip_code(tag):\n",
    "                    audit_zip_codes(zip_code_formats, zip_codes_distribution, tag.attrib['v'])\n",
    "                    \n",
    "                # Audit street types\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "                    \n",
    "                # Audit phone numbers\n",
    "                if is_phone(tag):\n",
    "                    audit_phone_number_formats(phone_number_formats, tag.attrib['v'])\n",
    "                    \n",
    "    osm_file.close()\n",
    "    \n",
    "    print('==================================================')\n",
    "    print('Auditing zip codes:')\n",
    "    print('==================================================')\n",
    "    print('Zip code formats:')\n",
    "    pprint.pprint(dict(zip_code_formats))\n",
    "    print()\n",
    "    print('--------------------------------------------------')\n",
    "    print('Zip code distribution:')\n",
    "    pprint.pprint(dict(zip_codes_distribution))\n",
    "    print()\n",
    "    \n",
    "    print('==================================================')\n",
    "    print('Auditing street types:')\n",
    "    print('==================================================')\n",
    "    pprint.pprint(dict(street_types))\n",
    "    print()\n",
    "    \n",
    "    print('==================================================')\n",
    "    print('Auditing phone number formats:')\n",
    "    print('==================================================')\n",
    "    pprint.pprint(dict(phone_number_formats))\n",
    "\n",
    "audit(OSM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3 Overview of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Importing Data into SQL Database\n",
    "\n",
    "I will start by parsing the elements in the XML file and update zip codes, street types and telephone numbers, then transform these elements from document format to\n",
    "tabular format and eventually into csv files. After that, I will import these csv files into a SQL database as tables for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSM_PATH = OSM_FILE\n",
    "\n",
    "NODES_PATH = 'nodes.csv'\n",
    "NODE_TAGS_PATH = 'nodes_tags.csv'\n",
    "WAYS_PATH = 'ways.csv'\n",
    "WAY_NODES_PATH = 'ways_nodes.csv'\n",
    "WAY_TAGS_PATH = 'ways_tags.csv'\n",
    "\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]') # Tags with problematic characters\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "\n",
    "def shape_element_attribs(element, attr_fields):\n",
    "    '''Convert an XML element to a dictionary \"node\" or \"way\", with keys in attr_fields'''\n",
    "    attribs = {}\n",
    "    element_attribs = element.attrib\n",
    "    for attr_field in attr_fields:\n",
    "        attribs[attr_field] = element_attribs[attr_field]\n",
    "    return attribs\n",
    "\n",
    "def shape_element_tags(element, problem_chars, default_tag_type, id):\n",
    "    '''Convert all tags of an XML element to a dictionary \"node_tags\" or \"way_tags\"'''\n",
    "    tags = []\n",
    "    element_tags = element.findall('tag')\n",
    "    if element_tags:\n",
    "        for element_tag in element_tags:\n",
    "            k_value = element_tag.get('k')\n",
    "            v_value = element_tag.get('v')\n",
    "            \n",
    "            # If the tag \"k\" value contains problematic characters, the tag should be ignored\n",
    "            if not re.search(problem_chars, k_value):\n",
    "                \n",
    "                tag ={}\n",
    "                tag['id'] = id \n",
    "                \n",
    "                # If the tag \"k\" value contains a \":\" \n",
    "                # the characters before the \":\" should be set as the tag type\n",
    "                # and characters after the \":\" should be set as the tag key\n",
    "                # If there are additional \":\" in the \"k\" value\n",
    "                # they should be ignored and kept as part of the tag key.\n",
    "                # e.g. <tag k=\"addr:street:name\" v=\"Lincoln\"/> should be turned into\n",
    "                # {'id': 12345, 'key': 'street:name', 'value': 'Lincoln', 'type': 'addr'}\n",
    "                \n",
    "                if ':' in k_value:\n",
    "                    tag['type'], tag['key'] = k_value.split(':', 1)\n",
    "                else:\n",
    "                    tag['key'] = k_value\n",
    "                    tag['type'] = default_tag_type\n",
    "                    \n",
    "                if k_value == 'addr:street':\n",
    "                    tag['value'] = update_name(v_value, mapping) # Update the street type\n",
    "                elif k_value == \"phone\" or k_value == 'contact:phone':\n",
    "                    tag['value'] = update_phone_number(v_value) # Update the phone number format\n",
    "                else:\n",
    "                    tag['value'] = v_value\n",
    "                \n",
    "                tags.append(tag)\n",
    "    return tags\n",
    "\n",
    "def shape_element_way_nodes(element, id):\n",
    "    '''Convert an XML element of \"way\" into a dictionary \"way_nodes\"'''\n",
    "    way_nodes = []\n",
    "    way_nodes_tags = element.findall('nd')\n",
    "    for index, way_node_tag in enumerate(way_nodes_tags):\n",
    "        way_node = {}\n",
    "        way_node['id'] = id\n",
    "        way_node['node_id'] = way_node_tag.get('ref')\n",
    "        way_node['position'] = index\n",
    "        way_nodes.append(way_node)\n",
    "    return way_nodes\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    '''Clean and shape node or way XML element to a dictionary'''\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        node_attribs = shape_element_attribs(element, node_attr_fields)\n",
    "        node_id = node_attribs['id']\n",
    "        tags = shape_element_tags(element, problem_chars, default_tag_type, node_id)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        way_attribs = shape_element_attribs(element, way_attr_fields)\n",
    "        way_id = way_attribs['id']\n",
    "        tags = shape_element_tags(element, problem_chars, default_tag_type, way_id)\n",
    "        way_nodes = shape_element_way_nodes(element, way_id)           \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    '''Yield element if it is the right type of tag'''\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in):\n",
    "    '''Iteratively process each XML element and write to csv(s)\n",
    "    \n",
    "    Arg:\n",
    "    file_in: an OSM XML file to be converted\n",
    "    '''\n",
    "\n",
    "    with open(NODES_PATH, 'w', encoding='utf-8') as nodes_file, \\\n",
    "         open(NODE_TAGS_PATH, 'w', encoding='utf-8') as nodes_tags_file, \\\n",
    "         open(WAYS_PATH, 'w', encoding='utf-8') as ways_file, \\\n",
    "         open(WAY_NODES_PATH, 'w', encoding='utf-8') as way_nodes_file, \\\n",
    "         open(WAY_TAGS_PATH, 'w', encoding='utf-8') as way_tags_file:\n",
    "\n",
    "        nodes_writer = csv.DictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = csv.DictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = csv.DictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = csv.DictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = csv.DictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "process_map(OSM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing nodes.csv\n",
      "0 seconds: completed 200000 rows\n",
      "2 seconds: completed 400000 rows\n",
      "5 seconds: completed 600000 rows\n",
      "8 seconds: completed 800000 rows\n",
      "10 seconds: completed 1000000 rows\n",
      "13 seconds: completed 1200000 rows\n",
      "16 seconds: completed 1400000 rows\n",
      "18 seconds: completed 1600000 rows\n",
      "21 seconds: completed 1800000 rows\n",
      "23 seconds: completed 2000000 rows\n",
      "Processing nodes_tags.csv\n",
      "0 seconds: completed 200000 rows\n",
      "1 seconds: completed 400000 rows\n",
      "Processing ways.csv\n",
      "0 seconds: completed 200000 rows\n",
      "2 seconds: completed 400000 rows\n",
      "Processing ways_tags.csv\n",
      "0 seconds: completed 200000 rows\n",
      "2 seconds: completed 400000 rows\n",
      "4 seconds: completed 600000 rows\n",
      "5 seconds: completed 800000 rows\n",
      "7 seconds: completed 1000000 rows\n",
      "9 seconds: completed 1200000 rows\n",
      "11 seconds: completed 1400000 rows\n",
      "12 seconds: completed 1600000 rows\n",
      "14 seconds: completed 1800000 rows\n",
      "Processing ways_nodes.csv\n",
      "0 seconds: completed 200000 rows\n",
      "1 seconds: completed 400000 rows\n",
      "2 seconds: completed 600000 rows\n",
      "3 seconds: completed 800000 rows\n",
      "5 seconds: completed 1000000 rows\n",
      "6 seconds: completed 1200000 rows\n",
      "7 seconds: completed 1400000 rows\n",
      "8 seconds: completed 1600000 rows\n",
      "10 seconds: completed 1800000 rows\n",
      "11 seconds: completed 2000000 rows\n",
      "12 seconds: completed 2200000 rows\n",
      "14 seconds: completed 2400000 rows\n",
      "15 seconds: completed 2600000 rows\n",
      "16 seconds: completed 2800000 rows\n"
     ]
    }
   ],
   "source": [
    "# ================================================== #\n",
    "#                    Database                        #\n",
    "# ================================================== #\n",
    "\n",
    "engine = create_engine('sqlite:///manhattan.db') # Database connection\n",
    "\n",
    "# Create tables\n",
    "metadata = MetaData()\n",
    "\n",
    "nodes = Table('nodes', metadata,\n",
    "    Column('id', Integer, primary_key=True, nullable=False),\n",
    "    Column('lat', Float),\n",
    "    Column('lon', Float),\n",
    "    Column('user', String),\n",
    "    Column('uid', Integer),\n",
    "    Column('version', String),\n",
    "    Column('changeset', Integer),\n",
    "    Column('timestamp', String)\n",
    ")\n",
    "\n",
    "nodes_tags = Table('nodes_tags', metadata,\n",
    "    Column('id', Integer, ForeignKey('nodes.id'), nullable=False),\n",
    "    Column('key', String),\n",
    "    Column('value', String),\n",
    "    Column('type', String),\n",
    ")\n",
    "\n",
    "ways = Table('ways', metadata,\n",
    "    Column('id', Integer, primary_key=True, nullable=False),\n",
    "    Column('user', String),\n",
    "    Column('uid', Integer),\n",
    "    Column('version', String),\n",
    "    Column('changeset', Integer),\n",
    "    Column('timestamp', String)\n",
    ")\n",
    "\n",
    "ways_tags = Table('ways_tags', metadata,\n",
    "    Column('id', Integer, ForeignKey('ways.id'), nullable=False),\n",
    "    Column('key', String),\n",
    "    Column('value', String),\n",
    "    Column('type', String),\n",
    ")\n",
    "\n",
    "ways_nodes = Table('ways_nodes', metadata,\n",
    "    Column('id', Integer, ForeignKey('ways.id'), nullable=False),\n",
    "    Column('node_id', Integer, ForeignKey('nodes.id'), nullable=False),\n",
    "    Column('position', Integer, nullable=False)\n",
    ")\n",
    "\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Load csv files in chunks into Pandas DataFrames, then append them into SQLite database \n",
    "# https://plot.ly/python/big-data-analytics-with-pandas-and-sqlite/\n",
    "# http://www.mapfish.org/doc/tutorials/sqlalchemy.html\n",
    "\n",
    "def csv_to_db(csvfile, table):\n",
    "    print('Processing {}'.format(csvfile))\n",
    "    start = dt.datetime.now()\n",
    "    chunksize = 200000\n",
    "    j = 0\n",
    "    for df in pd.read_csv(csvfile, chunksize=chunksize, iterator=True, encoding='utf-8'):\n",
    "        j+=1\n",
    "        print('{} seconds: completed {} rows'.format((dt.datetime.now() - start).seconds, j*chunksize))\n",
    "        df.to_sql(table, engine, if_exists='append', index=False)\n",
    "\n",
    "csv_to_db('nodes.csv', 'nodes')\n",
    "csv_to_db('nodes_tags.csv', 'nodes_tags')\n",
    "csv_to_db('ways.csv', 'ways')\n",
    "csv_to_db('ways_tags.csv', 'ways_tags')\n",
    "csv_to_db('ways_nodes.csv', 'ways_nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Overview Statistics of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Size\n",
    "\n",
    "| File Name                | File Size (MB) |\n",
    "|--------------------------|----------------|\n",
    "| NYC.osm                  | 477.565        |\n",
    "| manhattan.db             | 280.372        |\n",
    "| nodes.csv                | 169.271        |\n",
    "| nodes_tags.csv           |  10.277        |\n",
    "| ways.csv                 |  21.063        |\n",
    "| ways_tags.csv            |  64.331        |\n",
    "| ways_nodes.csv           |  54.527        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Unique Users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Unique Users\n",
       "0                    2163"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = '''\n",
    "SELECT COUNT(*) AS \"Number of Unique Users\" FROM\n",
    "(SELECT uid FROM nodes \n",
    "UNION\n",
    "SELECT uid FROM ways) nodes_ways_uids;\n",
    "'''\n",
    "df = pd.read_sql_query(sql_query, engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1884748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Nodes\n",
       "0          1884748"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = '''\n",
    "SELECT COUNT(*) AS \"Number of Nodes\" FROM nodes\n",
    "'''\n",
    "df = pd.read_sql_query(sql_query, engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Ways</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Ways\n",
       "0          320048"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = '''\n",
    "SELECT COUNT(*) AS \"Number of Ways\" FROM ways\n",
    "'''\n",
    "df = pd.read_sql_query(sql_query, engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of subway stations\n",
    "New York is famous for its spanning subway network that connects the city together. I would like to know how many subway stations out of the total 422 stations are included in our extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Subway Stations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Subway Stations\n",
       "0                        378"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = '''\n",
    "SELECT COUNT(*) AS \"Number of Subway Stations\" \n",
    "FROM nodes_tags \n",
    "WHERE value=\"New York City Subway\";\n",
    "'''\n",
    "df = pd.read_sql_query(sql_query, engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 cuisines\n",
    "New York is also the heaven for foodies with all kinds of cuisines from around the world. It is interesting to figure out what are the most popular cuisines in the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cuisine Types</th>\n",
       "      <th>Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>italian</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pizza</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>american</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexican</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chinese</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>japanese</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>french</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>indian</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thai</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>burger</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cuisine Types  Num\n",
       "0       italian  134\n",
       "1         pizza   88\n",
       "2      american   85\n",
       "3       mexican   79\n",
       "4       chinese   62\n",
       "5      japanese   46\n",
       "6        french   44\n",
       "7        indian   43\n",
       "8          thai   43\n",
       "9        burger   42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = '''\n",
    "SELECT value AS \"Cuisine Types\", COUNT(*) AS Num \n",
    "FROM nodes_tags \n",
    "JOIN (SELECT DISTINCT id FROM nodes_tags WHERE value=\"restaurant\") nodes_ids\n",
    "ON nodes_tags.id=nodes_ids.id\n",
    "WHERE key=\"cuisine\" \n",
    "GROUP BY value \n",
    "ORDER BY COUNT(*) DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "df = pd.read_sql_query(sql_query, engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 cafes\n",
    "New Yorkers cannot live without their coffee. By looking at the top 10 cafe shops with most locations, I found out there are other problems in the dataset, such as Starbucks has \"Starbucks\" and \"Starbucks Coffee\" two different naming conventions, also Dunkin' Donuts has \"Dunkin' Donuts\" and \"Dunkin Donuts\" two different names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cafe Shop Names</th>\n",
       "      <th>Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dunkin' Donuts</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Starbucks Coffee</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Pain Quotidien</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cafe Grumpy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dunkin Donuts</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Piccolo Cafe</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pinkberry</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pret a Manger</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Coffee Bean &amp; Tea Leaf</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Cafe Shop Names  Num\n",
       "0                   Starbucks  114\n",
       "1              Dunkin' Donuts   33\n",
       "2            Starbucks Coffee   24\n",
       "3           Le Pain Quotidien   13\n",
       "4                 Cafe Grumpy    4\n",
       "5               Dunkin Donuts    4\n",
       "6                Piccolo Cafe    4\n",
       "7                   Pinkberry    4\n",
       "8               Pret a Manger    4\n",
       "9  The Coffee Bean & Tea Leaf    4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = '''\n",
    "SELECT value AS \"Cafe Shop Names\", COUNT(*) AS Num \n",
    "FROM nodes_tags \n",
    "JOIN (SELECT DISTINCT id FROM nodes_tags WHERE value=\"cafe\") nodes_ids\n",
    "ON nodes_tags.id=nodes_ids.id\n",
    "WHERE key=\"name\" \n",
    "GROUP BY value \n",
    "ORDER BY COUNT(*) DESC  \n",
    "LIMIT 10;'''\n",
    "\n",
    "df = pd.read_sql_query(sql_query, engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Other Ideas about the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Ratings\n",
    "One piece of crucial information missing from the dataset is the ratings of places. By incorporating a node tag with user ratings can help user answer questions such as \"What are some of the best restaurants in town?\", \"Which doctor in my neighborhood should I go to?\".\n",
    "\n",
    "I can think of two ways to gather this rating information:\n",
    "1. User contribution. It's easy to implement this, but the problem is the number of active contributing users for our OpenStreetMap data is low, so the ratings will not have a sample size large enough to be representative.\n",
    "2. Aggregate from other web sources. This approach can get good ratings information fast and more accurate than the first approach. But the problem is how to get permissions from other sources to provide their rating data, not to mention that those sources are probably OpenStreetMap's direct and indirect competitors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Conclusion\n",
    "\n",
    "This analysis of OpenStreetMap Manhattan extract has helped me dig into the problems and inconsistency of the OpenStreetMap data. After cleaning zip codes, address types and phone numbers of this dataset, I imported this dataset into a SQL database for further exploration. I obtained some statistics and answered some questions using SQL queries, but I also found some questions that couldn't be anwsered without incorporating user ratings into our dataset.\n",
    "\n",
    "I really liked this project, and if all our Udacians can incorporate our cleaned data and other ideas to improve the dataset of OpenStreepMap, I believe it will make OpenStreepMap cleaner and more popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
